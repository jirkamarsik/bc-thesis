\chapter{Maximum Entropy Modelling}
\label{chap:maxent}

In this chapter we present the principles of maximum entropy modelling, how
maximum entropy models relate to exponential models and how a maximum entropy
model is induced from data. We also discuss which implementations of the
technique are available and which one was used in our system.

\section{Maximum Entropy Models}
\label{chap:maxent-maxent} 

We want to construct a probabilistic model which gives us a probability
$p(a,b)$ of an outcome\footnote{The terminology used in computational
linguistics often clashes with the one used in probability theory. What is in
probability theory usually known as an outcome is here referred to as an
\newterm{event}. These events are pairs of \newterm{contexts} and
\newterm{outcomes}, where the context is the data we have available when we
want a prediction and the outcome is what we want to predict.} $a$ occuring
with context $b$. We want this model to be very close to the observed training
data, meaning that the data's probability given our model $p$ is high.

However, we do not want the maximum likelihood model because we
are aware that the observed data does not cover all the possible situations.
Instead, we want a model that shares a lot of properties with the observed
data. We express these properties as binary functions on the space of events
$E$ and we call these functions \newterm{features}\footnote{The term features
is also commonly used in machine learning to denote a part of the context. When
it will be important to differentiate these two meaning in other parts of the
work, the term \newterm{maximum entropy features} will be used to refer to the
features defined here.}. In most implementations, including ours, these binary
features are restricted to the following form

\begin{equation}
\label{eq:common-feature}
f(a,b) =
\begin{cases}
  1 & \text{if } a=o \text{ and } p(b) \\
  0 & \text{else}
\end{cases}
\end{equation}

where $o$ is an outcome and $p$ is a context predicate. We want the constructed
model $p$ to share the expected values of these feature functions with the
empirical model $\bar{p}$. What this means is that the probability of $f(a,b)$
being 1 is the same in both models.

Let us say we have chosen several such features we want retained in our model,
now we need to select some model from the set of complying models. This is the
point where the maximum entropy entropy principle comes into play. The basic
idea of the maximum entropy principle was nicely hinted at by Laplace:

\begin{quote}
When one has no information to distinguish between the probability of two
events, the best strategy is to consider them equally likely.
\end{quote}

We would like to have a distribution which conforms to the requirements imposed
by the features but is otherwise unbiased, it is as close to uniform as
possible without violating the features' requirements. A standard measure of
the uniformity of a distribution is entropy

\[
H(p) = -\sum_{x \in E} p(x) \log p(x)
\]

We would like to find a distribution which adheres to the features' constraints
and maximizes the maximum entropy. It can be shown (see e.g.\ Ratnaparkhi) that
the such a distribution is of the following form

\begin{equation}
\label{eq:exp-model}
p(x) = \pi \prod_{j=1}^k \alpha_j^{f_j(x)}
\end{equation}

where $f_j(x)$ for $j \in \{1,\dotsc,k\}$ are the features we want to retain
and $0 < \alpha_j,\pi < \infty$. More interestingly, the maximum entropy model
adhering to the features' constraints is equal to the maximum likelihood model
having the shape in \ref{eq:exp-model} (we call them \newterm{exponential
models}). 

Given the set of features we want to retain in our model, we can now employ an
unrestricted optimization algorithm to find the parameters of the exponential
model which maximize the likelihood of the training data.

Once we wrap our minds around the definition of an exponential model and the
possible features from \ref{eq:common-feature}, we can see that when predicting
an outcome given a context, each predicate which holds for the context votes
for each outcome by multiplying its probability. The probability is multiplied
by the parameter of the exponential model corresponding to the feature which
is constructed from the outcome and predicate in question. The probability is
either increased or decreased depending on how often was that predicate
encountered with the same outcome in the training data.

In practice, the features (in the machine learning sense of the word) being
passed to the maximum entropy classifier are the predicates which combine with
the outcomes to form the maximum entropy features.

\section{Available Implementations}
\label{sec:maxent-impl}

There are several notable implementations of maximum entropy estimators
available. The one we chose for our tokenizer was the Maximum Entropy Modeling
Toolkit for Python and C++ written by Zhang Le. The toolkit offers a nice clean
API with which we are able to feed training events to the estimator and then
launch a training procedure which finds the optimal parameters. The resulting
model can be easily saved to a file and loaded later. The API is complete with
functions for evaluating the probabilities of $(context, outcome)$ pairs and
derived convenience functions for predicting outcomes from contexts. The
supported parameter estimation algorithms include GIS and L-BFGS. The L-BFGS
implementation provided by Jorge Nocedal is written in Fortran with large scale
datasets in mind. When the various algorithms for estimating the parameters of
a maximum entropy model were evaluated, L-BFGS clearly outdid the GIS, IIS,
gradient and conjugate gradient algorithms.

Other implementations were contemplated, however they would require more effort
to integrate seamlessly into our tokenizer. The main reason behind this is
that the abovementioned toolkit is the only one supplying a C++ API. The other
toolkits only have either command line interfaces or are written in different
languages. Of these toolkits, only a few offer anything worth the effort.

Our problem with the toolkits written in Python and Java (the most notable
being NLTK and the Stanford Classifier) is that while predicting an outcome of
a potential boundary, we rely on the disambiguation of the preceding
boundaries. This means that if we were to use NLTK or the Stanford Classifier
for prediction, we would have to switch from C++ to Java or Python to perform
the disambiguation for every ambiguous boundary individually. This could be
worked around by using the toolkits only for training and then writing our own
implementation of the exponential model's evaluate functions.

But even if we did integrate these alternative implementation, the Java
implementations would have a hard time outperforming the Fortran L-BFGS
implementation. The methods in SciPy might be more viable though.

The only alternative solution which looked intriguing is the Toolkit for
Advanced Discriminative Modeling (TADM) by Robert Malouf. The toolkit lacks an
API and relies only on a command line interface. This would mean that during
training the collected events would have to be stored in a file and TADM would
have to be invoked using the \funcname{system} function. An implementation of
an exponential model would then be needed including loading the model from the
file, evaluating the probabilities of events and predicting the most probable
outcome.

Howver, if too much time is spent estimating the model's parameters on a
machine which might benefit from the PETSc and TAO optimizations used in TADM,
it might be worthwhile to change the tokenizer to use TADM.
