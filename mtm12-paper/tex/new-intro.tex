\section{Introduction}
\label{sec:introduction}

Tokenization and segmentation are parts of almost every natural
language processing system, since in most of the higher-level language
processing applications, words and sentences are the basic processing
units, not streams of bytes encoding characters.

Segmentation (a term we use for what is also referred to as sentence
detection or sentence boundary disambiguation) has been tackled using
a variety of techniques. The most common approaches include writing
heuristics and constructing abbreviation lists (the Stanford
Tokenizer, the RE system) or using machine learning algorithms to
predict the role of a potential sentence terminator (Satz,
MxTerminator, Apache OpenNLP). There have also recently been some very
successful systems using unsupervised methods (Punkt).

Tokenization is a problem which stops being trivial when we start
considering whitespace-free languages such as Chinese or Japanese. In
these languages, tokenization (also referred to as word segmentation)
receives a lot of attention \cite{seg-bakeoff}.

TrTok aims to be a practical tool for tokenizing and segmenting text
written in any language. To achieve such a goal, TrTok relies on the
user determining the specifics of training and tokenization and
providing the necessary training data.

TrTok's novelty comes in the openness and formalization of the
tokenization process and in its resulting general applicability. It is
a continuation of the approach outlined by \citet{sbd-trtok-orig}. The
process is divided into several discrete stages, most of which are
heavily customizable. For example, the user is able to say where in
the text should TrTok consider breaking up or joining tokens or
sentences, how should TrTok represent the context of these decision
points to the underlying classifier, how should the classifier be
trained, how should existing whitespace be treated and more.

TrTok was also built to be a practical tool, which means it can
transparently process text interspersed with XML markup and HTML
entities and was designed to run fast.

The major inconveniences of TrTok are that due to its customizability
it needs to be properly set up and due to its reliance on machine
learning methods, it requires manually tokenized training data.
